{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b3d2c1-0c23-48aa-bfbd-b63326da37b7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Processing Benchmarking Results\n",
    "This notebook is meant to be run with results.csv, included in the same directory. Results.csv was generated from benchmark_A.py with the following settings:\\\n",
    "n: integer values from 5 to 20\\\n",
    "k = n // 5\\\n",
    "q = 0.5\\\n",
    "number_of_trials = 6. Note we discard the first trial since GPT model is warming up, and only record the following 5 trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7bbc0-1abd-49e5-b7a6-c36addfad254",
   "metadata": {},
   "source": [
    "# Step 1: Compute Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5548b5f-d24e-49c8-937a-30b19ddc2553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'compute_average' from 'utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mu\u001b[39;00m \u001b[38;5;66;03m# utility files to help make code clean and readable\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_average\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Loads data from csv file. \u001b[39;00m\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mopen_csv_results(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'compute_average' from 'utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils.utuils as u # utility files to help make code clean and readable\n",
    "from utils.utils import compute_average\n",
    "\n",
    "# Loads data from csv file. \n",
    "data = u.open_csv_results('results.csv')\n",
    "\n",
    "# Takes csv data, chunks the data by node size, and computes standard deviation for each node size. Sends back zipped files\n",
    "zipped, zipped_stds = u.df_to_slices(data)\n",
    "\n",
    "# Unzip standard deviations\n",
    "(\n",
    "    _, \n",
    "    qokit_time_stds, # Standard deviation for qokit runtime\n",
    "    gpt_time_stds, # Standard deviation for GPT runtime\n",
    "    qokit_ar_stds, # Standard deviation for QOKit approximation Ratios\n",
    "    gpt_ar_stds, # Standard deviation for GPT approximation Ratios\n",
    "    qokit_mem_stds, # Standard deviation for QOKit RAM usage\n",
    "    gpt_mem_stds # Standard deviation for GPT RAM usage\n",
    ") = zip(*zipped_stds)\n",
    "\n",
    "# Lists to hold x and y values\n",
    "# After the for loop, these variables will hold similar to a pandas dataframe:\n",
    "\"\"\"\n",
    "Node Size, Average QOKit Times, Average GPT Times, Average QOKit AR, Average GPT AR, Average QOKit Ram, Average GPT Ram\n",
    "5            .                      .                    .                 .            .                   .\n",
    "6            .                      .                    .                 .            .                   .\n",
    ".            .                      .                    .                 .            .                   .\n",
    ".            .                      .                    .                 .            .                   .\n",
    ".            .                      .                    .                 .            .                   .\n",
    "20            .                      .                    .                 .            .                   .\n",
    "\"\"\"\n",
    "node_counts = []\n",
    "qokit_times = []\n",
    "gpt_times = []\n",
    "qokit_ars = []\n",
    "gpt_ars = []\n",
    "qokit_mems = []\n",
    "gpt_mems = []\n",
    "\n",
    "# We iterate over the zipped object, calcualting the average value for each benchmark for each node size\n",
    "for node, qokit_time, gpt_time, qokit_ar, gpt_ar, qokit_peak_memory, gpt_peak_memory in zipped:\n",
    "    node_counts.append(compute_average(_)) \n",
    "    qokit_times.append(compute_average(qokit_time))\n",
    "    gpt_times.append(compute_average(gpt_time))\n",
    "    qokit_ars.append(compute_average(qokit_ar))\n",
    "    gpt_ars.append(compute_average(gpt_ar))\n",
    "    qokit_mems.append(compute_average(qokit_peak_memory))\n",
    "    gpt_mems.append(compute_average(gpt_peak_memory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e760cd-463c-4fc2-9b11-46645807eb9a",
   "metadata": {},
   "source": [
    "# Step 2: Display Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8db07b-40c3-4315-967a-ba6b4aaa8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime for QOKit and GPT model as a function of the number of nodes. Error bars are included for both. For GPT model, they are too small for Matplotlib to render\n",
    "u.draw_plot(\n",
    "    x=node_counts,\n",
    "    y_series=[qokit_times, gpt_times],\n",
    "    y_errors=[qokit_time_stds, gpt_time_stds],  # pass std devs here\n",
    "    labels=[\"QOKit Time (s)\", \"GPT Time (s)\"],\n",
    "    xlabel=\"Number of Nodes\",\n",
    "    ylabel=\"Runtime (seconds)\",\n",
    "    title=\"Runtime vs Number of Nodes\",\n",
    "    yscale= \"linear\",\n",
    "    show_grid=True,\n",
    "    filename='time_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699c913-0ae6-4b2e-9b25-c421a4a4a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same data displayed on above graph. This is a logirthmic plot\n",
    "u.draw_plot(\n",
    "    x=node_counts,\n",
    "    y_series=[qokit_times, gpt_times],\n",
    "    y_errors=[qokit_time_stds, gpt_time_stds],  # pass std devs here\n",
    "    labels=[\"QOKit Time (s)\", \"GPT Time (s)\"],\n",
    "    xlabel=\"Number of Nodes\",\n",
    "    ylabel=\"Runtime (seconds)\",\n",
    "    title=\"Runtime vs Number of Nodes\",\n",
    "    yscale= \"log\",\n",
    "    show_grid=False,\n",
    "    filename='time_comparison_log.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7988a-86c0-4981-8b25-64696741be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation ratio as a function of the number of nodes. We expect the GPT model to decline in AR quality.\n",
    "u.draw_plot(\n",
    "    x=node_counts,\n",
    "    y_series=[qokit_ars, gpt_ars],\n",
    "    y_errors=[qokit_ar_stds, gpt_ar_stds],\n",
    "    labels=[\"QOKit AR\", \"GPT AR\"],\n",
    "    xlabel=\"Number of Nodes\",\n",
    "    ylabel=\"Approximation Ratio\",\n",
    "    title=\"Approximation Ratio vs Number of Nodes\",\n",
    "    filename = \"AR_comparison.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f84dd-73b8-449f-9cb0-374f42db4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAM usage as a function of node count for QOKit and GPT mpdel \n",
    "u.draw_plot(\n",
    "    x=node_counts,\n",
    "    y_series=[qokit_mems, gpt_mems],\n",
    "    y_errors=[qokit_mem_stds, gpt_mem_stds],\n",
    "    labels=[\"QOKit Peak Memory (MB)\", \"GPT Peak Memory (MB)\"],\n",
    "    xlabel=\"Number of Nodes\",\n",
    "    ylabel=\"Memory (MB)\",\n",
    "    title=\"Peak RAM Usage vs Number of Nodes\",\n",
    "    filename='memory_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254e2b6-75ea-407e-ac72-5dd61a00c75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f3315-1af6-4807-baaa-337523027f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
